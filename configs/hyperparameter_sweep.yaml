# hyperparameter_sweep.yaml - Example hyperparameter optimization
tool: hello-world

defaults:
  - _self_

experiment:
  name: "hyperparameter_sweep"
  seed: 42
  description: "Hyperparameter optimization experiment"

model:
  name: "sweep_model"
  hidden_size: 64  # Will be swept
  num_layers: 3    # Will be swept
  dropout: 0.1

data:
  batch_size: 32
  num_workers: 4

trainer:
  max_epochs: 50
  learning_rate: 0.001

hydra:
  run:
    dir: outputs/hyperparameter_sweep/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    params:
      model.hidden_size: 64,128,256
      model.num_layers: 2,3,4
